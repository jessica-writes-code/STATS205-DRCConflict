View(fb.adj.orig)
sum(fb.adj.orig[1,])
rm(list=ls())
input <- "/Users/jmoore523/Dropbox/Graduate School/Q3 - Spring 2016/STATS315B/Assignment 3/Individual Work/Input"
library(nnet)
spam <- read.csv(paste0(input,"/Spam_Data.txt"), header=FALSE)
spam.train <- read.csv(paste0(input,"/Spam_Train.txt"), header=FALSE)
spam.test <- read.csv(paste0(input,"/Spam.Test.txt"), header=FALSE)
# Add Variable Names
spam.names <- c("word_freq_make","word_freq_address","word_freq_all","word_freq_3d",
"word_freq_our","word_freq_over","word_freq_remove","word_freq_internet",
"word_freq_order","word_freq_mail","word_freq_receive","word_freq_will",
"word_freq_people","word_freq_report","word_freq_addresses",
"word_freq_free","word_freq_business","word_freq_email","word_freq_you",
"word_freq_credit","word_freq_your","word_freq_font","word_freq_000",
"word_freq_money","word_freq_hp","word_freq_hpl","word_freq_george",
"word_freq_650","word_freq_lab","word_freq_labs","word_freq_telnet",
"word_freq_857","word_freq_data","word_freq_415","word_freq_85",
"word_freq_technology","word_freq_1999","word_freq_parts","word_freq_pm",
"word_freq_direct","word_freq_cs","word_freq_meeting",
"word_freq_original","word_freq_project","word_freq_re","word_freq_edu",
"word_freq_table","word_freq_conference","char_freq_;","char_freq_(",
"char_freq_[","char_freq_!","char_freq_$","char_freq_#",
"capital_run_length_average","capital_run_length_longest",
"capital_run_length_total","emailtype")
names(spam) <- spam.names
names(spam.train) <- spam.names
names(spam.test) <- spam.names
View(spam.test)
for (i in 1:57) {
spam.train[,i] <- scale(spam.train[,i])
spam.test[,i] <- scale(spam.test[,i])
}
View(spam.test)
?runif
wts <- runif(spam.train, min=-0.5, max=0.5)
View(spam.test)
wts <- runif(spam.train, min=-0.5, max=0.5)
nnet1 <- nnet(emailtype ~ ., data=spam.train, size = 1, Wts = wts)
wts <- runif(nrow(spam.train), min=-0.5, max=0.5)
nnet1 <- nnet(emailtype ~ ., data=spam.train, size = 1, Wts = wts)
wts <- runif(ncol(spam.train), min=-0.5, max=0.5)
nnet1 <- nnet(emailtype ~ ., data=spam.train, size = 1, Wts = wts)
?nnet
?sample
?nnet
wts <- runif(ncol(spam.train)-1, min=-0.5, max=0.5)
nnet1 <- nnet(emailtype ~ ., data=spam.train, size = 1, Wts = wts)
weights <- runif(ncol(spam.train)-1, min=-0.5, max=0.5)
nnet1 <- nnet(emailtype ~ ., data=spam.train, size = 1, Wts = wts)
nnet1 <- nnet(emailtype ~ ., data=spam.train, size = 1, Wts = weights)
weights <- runif(nrow(spam.train.sub1), min=-0.5, max=0.5)
nnet1 <- nnet(emailtype ~ ., data=spam.train.sub1, size = 1, Wts = weights)
# Load Training & Test Set
spam.train <- read.csv(paste0(input,"/Spam_Train.txt"), header=FALSE)
spam.test <- read.csv(paste0(input,"/Spam.Test.txt"), header=FALSE)
# Add Variable Names
spam.names <- c("word_freq_make","word_freq_address","word_freq_all","word_freq_3d",
"word_freq_our","word_freq_over","word_freq_remove","word_freq_internet",
"word_freq_order","word_freq_mail","word_freq_receive","word_freq_will",
"word_freq_people","word_freq_report","word_freq_addresses",
"word_freq_free","word_freq_business","word_freq_email","word_freq_you",
"word_freq_credit","word_freq_your","word_freq_font","word_freq_000",
"word_freq_money","word_freq_hp","word_freq_hpl","word_freq_george",
"word_freq_650","word_freq_lab","word_freq_labs","word_freq_telnet",
"word_freq_857","word_freq_data","word_freq_415","word_freq_85",
"word_freq_technology","word_freq_1999","word_freq_parts","word_freq_pm",
"word_freq_direct","word_freq_cs","word_freq_meeting",
"word_freq_original","word_freq_project","word_freq_re","word_freq_edu",
"word_freq_table","word_freq_conference","char_freq_;","char_freq_(",
"char_freq_[","char_freq_!","char_freq_$","char_freq_#",
"capital_run_length_average","capital_run_length_longest",
"capital_run_length_total","emailtype")
names(spam) <- spam.names
names(spam.train) <- spam.names
names(spam.test) <- spam.names
# Split Spam.Train into Training & Test Sets
## We use an 80/20 split.
ind <- sample(nrow(spam.train), nrow(spam.train)*.8)
spam.train.sub1 <- spam.train[ind]
spam.train.sub2 <- spam.train[-ind]
# Standardize Variables
## The sets are standardized separately,
## so that one has no influence on the others.
for (i in 1:57) {
spam.train.sub1[,i] <- scale(spam.train.sub1[,i])
spam.train.sub2[,i] <- scale(spam.train.sub2[,i])
spam.test[,i] <- scale(spam.test[,i])
}
# Load Training & Test Set
spam.train <- read.csv(paste0(input,"/Spam_Train.txt"), header=FALSE)
spam.test <- read.csv(paste0(input,"/Spam.Test.txt"), header=FALSE)
# Add Variable Names
spam.names <- c("word_freq_make","word_freq_address","word_freq_all","word_freq_3d",
"word_freq_our","word_freq_over","word_freq_remove","word_freq_internet",
"word_freq_order","word_freq_mail","word_freq_receive","word_freq_will",
"word_freq_people","word_freq_report","word_freq_addresses",
"word_freq_free","word_freq_business","word_freq_email","word_freq_you",
"word_freq_credit","word_freq_your","word_freq_font","word_freq_000",
"word_freq_money","word_freq_hp","word_freq_hpl","word_freq_george",
"word_freq_650","word_freq_lab","word_freq_labs","word_freq_telnet",
"word_freq_857","word_freq_data","word_freq_415","word_freq_85",
"word_freq_technology","word_freq_1999","word_freq_parts","word_freq_pm",
"word_freq_direct","word_freq_cs","word_freq_meeting",
"word_freq_original","word_freq_project","word_freq_re","word_freq_edu",
"word_freq_table","word_freq_conference","char_freq_;","char_freq_(",
"char_freq_[","char_freq_!","char_freq_$","char_freq_#",
"capital_run_length_average","capital_run_length_longest",
"capital_run_length_total","emailtype")
names(spam) <- spam.names
names(spam.train) <- spam.names
names(spam.test) <- spam.names
# Split Spam.Train into Training & Test Sets
## We use an 80/20 split.
ind <- sample(nrow(spam.train), nrow(spam.train)*.8)
spam.train.sub1 <- spam.train[ind,]
spam.train.sub2 <- spam.train[-ind,]
# Standardize Variables
## The sets are standardized separately,
## so that one has no influence on the others.
for (i in 1:57) {
spam.train.sub1[,i] <- scale(spam.train.sub1[,i])
spam.train.sub2[,i] <- scale(spam.train.sub2[,i])
spam.test[,i] <- scale(spam.test[,i])
}
weights <- runif(nrow(spam.train.sub1), min=-0.5, max=0.5)
nnet1 <- nnet(emailtype ~ ., data=spam.train.sub1, size = 1, Wts = weights)
nnet1 <- nnet(emailtype ~ ., data=spam.train.sub1, size = 1)
nnet.cur <- nnet(emailtype ~ ., data=spam.train.sub1, size = i)
i <- 1
nnet.cur <- nnet(emailtype ~ ., data=spam.train.sub1, size = i)
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i)
# Load Training & Test Set
spam.train <- read.csv(paste0(input,"/Spam_Train.txt"), header=FALSE)
spam.test <- read.csv(paste0(input,"/Spam.Test.txt"), header=FALSE)
# Add Variable Names
spam.names <- c("word_freq_make","word_freq_address","word_freq_all","word_freq_3d",
"word_freq_our","word_freq_over","word_freq_remove","word_freq_internet",
"word_freq_order","word_freq_mail","word_freq_receive","word_freq_will",
"word_freq_people","word_freq_report","word_freq_addresses",
"word_freq_free","word_freq_business","word_freq_email","word_freq_you",
"word_freq_credit","word_freq_your","word_freq_font","word_freq_000",
"word_freq_money","word_freq_hp","word_freq_hpl","word_freq_george",
"word_freq_650","word_freq_lab","word_freq_labs","word_freq_telnet",
"word_freq_857","word_freq_data","word_freq_415","word_freq_85",
"word_freq_technology","word_freq_1999","word_freq_parts","word_freq_pm",
"word_freq_direct","word_freq_cs","word_freq_meeting",
"word_freq_original","word_freq_project","word_freq_re","word_freq_edu",
"word_freq_table","word_freq_conference","char_freq_;","char_freq_(",
"char_freq_[","char_freq_!","char_freq_$","char_freq_#",
"capital_run_length_average","capital_run_length_longest",
"capital_run_length_total","emailtype")
names(spam) <- spam.names
names(spam.train) <- spam.names
names(spam.test) <- spam.names
# Split Spam.Train into Training & Test Sets
## We use an 80/20 split.
## We refer to the test set that is a subset of "Spam.Train"
## as "Test Set 1" and "Spam.Test" as "Spam.Test".
ind <- sample(nrow(spam.train), nrow(spam.train)*.8)
spam.train1 <- spam.train[ind,]
spam.test1[-ind,]
# Standardize Variables
## The sets are standardized separately,
## so that one has no influence on the others.
for (i in 1:57) {
spam.train1[,i] <- scale(spam.train1[,i])
spam.test1[,i] <- scale(spam.test1[,i])
spam.test[,i] <- scale(spam.test[,i])
}
# Load Training & Test Set
spam.train <- read.csv(paste0(input,"/Spam_Train.txt"), header=FALSE)
spam.test <- read.csv(paste0(input,"/Spam.Test.txt"), header=FALSE)
# Add Variable Names
spam.names <- c("word_freq_make","word_freq_address","word_freq_all","word_freq_3d",
"word_freq_our","word_freq_over","word_freq_remove","word_freq_internet",
"word_freq_order","word_freq_mail","word_freq_receive","word_freq_will",
"word_freq_people","word_freq_report","word_freq_addresses",
"word_freq_free","word_freq_business","word_freq_email","word_freq_you",
"word_freq_credit","word_freq_your","word_freq_font","word_freq_000",
"word_freq_money","word_freq_hp","word_freq_hpl","word_freq_george",
"word_freq_650","word_freq_lab","word_freq_labs","word_freq_telnet",
"word_freq_857","word_freq_data","word_freq_415","word_freq_85",
"word_freq_technology","word_freq_1999","word_freq_parts","word_freq_pm",
"word_freq_direct","word_freq_cs","word_freq_meeting",
"word_freq_original","word_freq_project","word_freq_re","word_freq_edu",
"word_freq_table","word_freq_conference","char_freq_;","char_freq_(",
"char_freq_[","char_freq_!","char_freq_$","char_freq_#",
"capital_run_length_average","capital_run_length_longest",
"capital_run_length_total","emailtype")
names(spam) <- spam.names
names(spam.train) <- spam.names
names(spam.test) <- spam.names
# Split Spam.Train into Training & Test Sets
## We use an 80/20 split.
## We refer to the test set that is a subset of "Spam.Train"
## as "Test Set 1" and "Spam.Test" as "Spam.Test".
ind <- sample(nrow(spam.train), nrow(spam.train)*.8)
spam.train1 <- spam.train[ind,]
spam.test1[-ind,] <- spam.train[-ind,]
# Standardize Variables
## The sets are standardized separately,
## so that one has no influence on the others.
for (i in 1:57) {
spam.train1[,i] <- scale(spam.train1[,i])
spam.test1[,i] <- scale(spam.test1[,i])
spam.test[,i] <- scale(spam.test[,i])
}
# Load Training & Test Set
spam.train <- read.csv(paste0(input,"/Spam_Train.txt"), header=FALSE)
spam.test <- read.csv(paste0(input,"/Spam.Test.txt"), header=FALSE)
# Add Variable Names
spam.names <- c("word_freq_make","word_freq_address","word_freq_all","word_freq_3d",
"word_freq_our","word_freq_over","word_freq_remove","word_freq_internet",
"word_freq_order","word_freq_mail","word_freq_receive","word_freq_will",
"word_freq_people","word_freq_report","word_freq_addresses",
"word_freq_free","word_freq_business","word_freq_email","word_freq_you",
"word_freq_credit","word_freq_your","word_freq_font","word_freq_000",
"word_freq_money","word_freq_hp","word_freq_hpl","word_freq_george",
"word_freq_650","word_freq_lab","word_freq_labs","word_freq_telnet",
"word_freq_857","word_freq_data","word_freq_415","word_freq_85",
"word_freq_technology","word_freq_1999","word_freq_parts","word_freq_pm",
"word_freq_direct","word_freq_cs","word_freq_meeting",
"word_freq_original","word_freq_project","word_freq_re","word_freq_edu",
"word_freq_table","word_freq_conference","char_freq_;","char_freq_(",
"char_freq_[","char_freq_!","char_freq_$","char_freq_#",
"capital_run_length_average","capital_run_length_longest",
"capital_run_length_total","emailtype")
names(spam) <- spam.names
names(spam.train) <- spam.names
names(spam.test) <- spam.names
# Split Spam.Train into Training & Test Sets
## We use an 80/20 split.
## We refer to the test set that is a subset of "Spam.Train"
## as "Test Set 1" and "Spam.Test" as "Spam.Test".
ind <- sample(nrow(spam.train), nrow(spam.train)*.8)
spam.train1 <- spam.train[ind,]
spam.test1 <- spam.train[-ind,]
# Standardize Variables
## The sets are standardized separately,
## so that one has no influence on the others.
for (i in 1:57) {
spam.train1[,i] <- scale(spam.train1[,i])
spam.test1[,i] <- scale(spam.test1[,i])
spam.test[,i] <- scale(spam.test[,i])
}
i <- 1
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i)
predictions <- predict(nnet.cur, newdata=spam.test1)
sum(predictions)
predictions <- predict(nnet.cur, newdata=spam.test1, type='raw')
sum(predictions)
predictions <- predict(nnet.cur, newdata=spam.test1, type="raw")
sum(predictions)
?predict
predictions <- predict(nnet.cur, newdata=spam.test1, type=c("raw"))
predictions <- predict(nnet.cur, newdata=spam.test1, type=c("class"))
?nnet
table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass.table <- table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
misclass.table
sum(misclass.table)
misclass
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i)
predictions <- predict(nnet.cur, newdata=spam.test1)
preidctions
predictions
misclass.table <- table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
misclass.rate
misclass
source('~/.active-rstudio-document', echo=TRUE)
misclass
i <- 1
wts <- runif(59, min=-0.5, max=0.5)
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
wts <- runif(58, min=-0.5, max=0.5)
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
wts <- runif(60, min=-0.5, max=0.5)
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
# Vector for misclassification errors
misclass <- rep(NA,10)
# Fit one-hidden-layer NNs with 1 through 10 units in the hidden layer
for (i in 1:10) {
## Set different sets starting values for predictors
num.wts <- 57 + i + 2
wts <- runif(num.wts, min=-0.5, max=0.5)
## Fit NN
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
## Predict on Test Set 1
predictions <- predict(nnet.cur, newdata=spam.test1)
## Record misclassification error on test data
misclass.table <- table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
}
# Identify number of units w/ lowest misclass rate
which.min(misclass)
# Vector for misclassification errors
misclass <- rep(NA,10)
# Fit one-hidden-layer NNs with 1 through 10 units in the hidden layer
for (i in 1:10) {
## Set different sets starting values for predictors
num.wts <- 57 + i*2 + 1
wts <- runif(num.wts, min=-0.5, max=0.5)
## Fit NN
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
## Predict on Test Set 1
predictions <- predict(nnet.cur, newdata=spam.test1)
## Record misclassification error on test data
misclass.table <- table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
}
# Identify number of units w/ lowest misclass rate
which.min(misclass)
# Vector for misclassification errors
misclass <- rep(NA,10)
# Fit one-hidden-layer NNs with 1 through 10 units in the hidden layer
for (i in 1:10) {
## Set different sets starting values for predictors
num.wts <- 57 + i^2 + 2
wts <- runif(num.wts, min=-0.5, max=0.5)
## Fit NN
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
## Predict on Test Set 1
predictions <- predict(nnet.cur, newdata=spam.test1)
## Record misclassification error on test data
misclass.table <- table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
}
# Identify number of units w/ lowest misclass rate
which.min(misclass)
# Vector for misclassification errors
misclass <- rep(NA,10)
# Fit one-hidden-layer NNs with 1 through 10 units in the hidden layer
for (i in 1:10) {
## Set different sets starting values for predictors
num.wts <- 57*i + i + 2
wts <- runif(num.wts, min=-0.5, max=0.5)
## Fit NN
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
## Predict on Test Set 1
predictions <- predict(nnet.cur, newdata=spam.test1)
## Record misclassification error on test data
misclass.table <- table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
}
# Identify number of units w/ lowest misclass rate
which.min(misclass)
i <- 2
wts <- runif(57*i + i + 2, min=-0.5, max=0.5)
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
wts <- runif(120, min=-0.5, max=0.5)
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i)
nnet.cur$wts
length(nnet.cur$wts)
# Vector for misclassification errors
misclass <- rep(NA,10)
# Fit one-hidden-layer NNs with 1 through 10 units in the hidden layer
for (i in 1:10) {
## Set different sets starting values for predictors
num.wts <- 58*i + i + 1
wts <- runif(num.wts, min=-0.5, max=0.5)
## Fit NN
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = i, Wts = wts)
## Predict on Test Set 1
predictions <- predict(nnet.cur, newdata=spam.test1)
## Record misclassification error on test data
misclass.table <- table(predictions, spam.test1$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
}
# Identify number of units w/ lowest misclass rate
which.min(misclass)
predictions <- predict(nnet.cur, newdata=spam.test1, type='prob')
predictions <- predict(nnet.cur, newdata=spam.test1, type='raw')
predictions
seq(0,1,length.out=10)
seq(0,1,length.out=11)
nnet.cur$wts
?mean
?apply
source('~/.active-rstudio-document', echo=TRUE)
pred.final
pred1 <- fit.nn(wtdec)
wtdec
num.wts <- 58*best.units + best.units + 1
wts <- runif(num.wts, min=-0.5, max=0.5)
nnet.cur <- nnet(emailtype ~ ., data=spam.train, size = best.units, Wts = wts, decay = d)
d <- wtdec
nnet.cur <- nnet(emailtype ~ ., data=spam.train, size = best.units, Wts = wts, decay = d)
pred.curr <- predict(nnet.cur, newdata=spam.test, type='raw')
View(spam.test)
nnet.cur <- nnet(emailtype ~ ., data=spam.train, size = best.units, Wts = wts)
pred.curr <- predict(nnet.cur, newdata=spam.test, type='raw')
View(spam.test)
pred.curr <- predict(nnet.cur, newdata=spam.test1, type='raw')
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = best.units, Wts = wts, decay = d)
pred.curr <- predict(nnet.cur, newdata=spam.test, type='raw')
View(spam.train)
# Function to fit one-hidden-layer NN with 'best.units' units
fit.nn <- function(d) {
## Set different sets starting values for predictors
num.wts <- 58*best.units + best.units + 1
wts <- runif(num.wts, min=-0.5, max=0.5)
## Fit NN
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = best.units, Wts = wts, decay = d)
## Predict on 'Spam.Test'
pred.curr <- predict(nnet.cur, newdata=spam.test, type='raw')
return(pred.curr)
}
# Vector for misclassification errors
misclass <- rep(NA,10)
# Fit one-hidden-layer NN with 'best.units' units
# for 0, 0.1, ..., 1 values of weight decay
for (wtdec in seq(0,1,length.out=11)) {
## Create 10 runs with different starting values
pred1 <- fit.nn(wtdec)
pred2 <- fit.nn(wtdec)
pred3 <- fit.nn(wtdec)
pred4 <- fit.nn(wtdec)
pred5 <- fit.nn(wtdec)
pred6 <- fit.nn(wtdec)
pred7 <- fit.nn(wtdec)
pred8 <- fit.nn(wtdec)
pred9 <- fit.nn(wtdec)
pred10 <- fit.nn(wtdec)
## Average predictions
pred.all <- cbind(pred1, pred2, pred3, pred4, pred5, pred6, pred7, pred8, pred9, pred10)
pred.final <- apply(pred.all, 1, mean)
STOP
## Create binary prediction from probabilities
## Record misclassification error
misclass.table <- table(predictions, spam.test$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
}
pred.final.bin[pred.final.bin > 0.5] <- 1
pred.final.bin <- 0
pred.final.bin[pred.final > 0.5] <- 1
misclass.table <- table(pred.final.bin, spam.test$emailtype)
misclass.table
pred.final.bin <- 0
pred.final.bin <- rep(0, length(pred.final))
pred.final.bin[pred.final > 0.5] <- 1
## Record misclassification error
misclass.table <- table(pred.final.bin, spam.test$emailtype)
misclass.table
# Function to fit one-hidden-layer NN with 'best.units' units
fit.nn <- function(d) {
## Set different sets starting values for predictors
num.wts <- 58*best.units + best.units + 1
wts <- runif(num.wts, min=-0.5, max=0.5)
## Fit NN
nnet.cur <- nnet(emailtype ~ ., data=spam.train1, size = best.units, Wts = wts, decay = d)
## Predict on 'Spam.Test'
pred.curr <- predict(nnet.cur, newdata=spam.test, type='raw')
return(pred.curr)
}
# Vector for misclassification errors
misclass <- rep(NA,10)
# Fit one-hidden-layer NN with 'best.units' units
# for 0, 0.1, ..., 1 values of weight decay
for (wtdec in seq(0,1,length.out=11)) {
## Create 10 runs with different starting values
pred1 <- fit.nn(wtdec)
pred2 <- fit.nn(wtdec)
pred3 <- fit.nn(wtdec)
pred4 <- fit.nn(wtdec)
pred5 <- fit.nn(wtdec)
pred6 <- fit.nn(wtdec)
pred7 <- fit.nn(wtdec)
pred8 <- fit.nn(wtdec)
pred9 <- fit.nn(wtdec)
pred10 <- fit.nn(wtdec)
## Average predictions
pred.all <- cbind(pred1, pred2, pred3, pred4, pred5, pred6, pred7, pred8, pred9, pred10)
pred.final <- apply(pred.all, 1, mean)
## Create binary prediction from probabilities
pred.final.bin <- rep(0, length(pred.final))
pred.final.bin[pred.final > 0.5] <- 1
## Record misclassification error
misclass.table <- table(pred.final.bin, spam.test$emailtype)
misclass.rate <- (misclass.table[1,2] + misclass.table[2,1])/sum(misclass.table)
misclass[i] <- misclass.rate
}
misclass.rate
misclass
source('~/.active-rstudio-document', echo=TRUE)
misclass
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
m <- matrix(c(3,3,3,3), nrow=2)
m
chol(m)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
